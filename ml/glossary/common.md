## Основные термины и определения

Наблюдение может быть сплошным и выборочным. Сплошное - исследованию подвергается вся генеральная совокупность (все возможные и существующие случаи). Выборочное - из генеральной совокупности делается некоторая выборка, которая должна быть репрезентативной и на ее основе делается анализ и предсказание относительно всей генеральной совокупности.

В большинстве случаев нам приходится работать с выборочным наблюдением, поэтому мы должны понимать порядок ошибки, на величину которой наши предсказания могут отличаться параметры выборочного наблюдения от параметров сплошного наблюдения.

Выборочный показатель, который при многократном повторении выборки стремится к своему теоретическому значению, называется несмещенной оценкой.
Почему оценкой? Потому что мы не знаем реальное значение показателя (по генеральной совокупности), и с помощью выборочного наблюдения пытаемся его оценить. Оценка показателя – это есть его характеристика, рассчитанная по выборке. [1]

**Среднее арифметическое** - среднее значение по выборке  

**Математическое ожидание** - среднее значение случайной величины при стремлении количества выборок или количества её измерений (количества испытаний) к бесконечности  

**Выборочная средняя** – это несмещенная оценка математического ожидания, так как средняя из выборочных средних стремится к своему теоретическому значению по генеральной совокупности  

**Дисперсия** - мера разброса случайной величины относительно ее математического ожидания или, по-другому, это математическое ожидание отклонений от математического ожидания  

Несмещенность оценки – одна из важных характеристик статистического показателя. Смещенная оценка показателя заранее говорит о тенденции к ошибке. Поэтому показатели стараются оценивать таким образом, чтобы их оценки были несмещенными (как у средней арифметической). Чтобы решить проблему смещенности выборочной дисперсии, в ее расчет вносят корректировку – умножают на n/(n-1), либо сразу при расчете в знаменатель ставят не n, а n-1. [1]

Выборочная смещенная дисперсия:
![img](https://statanaliz.info/wp-content/uploads/2014/08/dispers_form_02.png)

Выборочная несмещенная дисперсия:
![img](https://statanaliz.info/wp-content/uploads/2014/08/dispers_form_nesm_01.png)

При большом объеме выборки (от 100 наблюдений) разница между смещенной и несмещенной дисперсиями практически исчезает.

**Стандартное откл-е/среднеквадратическое откл-е(std)** - показатель рассеивания значений случайной величины относительно её математического ожидания (равняется корню из дисперии)   
![img](https://wikimedia.org/api/rest_v1/media/math/render/svg/15619dfbb9a470d310c1bc08fb61d4fb1187d057)  

**Медиана** - значение, которое делит выборку таким образом, что ровно половина ее будет больше, а другая меньше. Медиана не обязательно совпадает со средним значением. Отклонение медианы от среднего называется перекосом данных  
<img src="./images/syb5i0F.png" width=500 alt="Divergence diagram" />

**skewness** - характеристика того, насколько сильно мода отличается от среднего  
skewness может быть положительным и отрицательным в зависимости от смещения распределения  

**Стандартная ошибка выборочного среднего** -  величина, характеризующая стандартное отклонение выборочного среднего, рассчитанное по выборке размера n из генеральной совокупности  
*центральная предельная теорема*: при извлечении некоторой выборки из генеральной совокупности выборочное среднее окажется в той же точке с ошибкой равной:  
![img](https://wikimedia.org/api/rest_v1/media/math/render/svg/a102289e0257e2be978ed66258079caacb9f1bae)  

**Уровень значимости** - обозначает вероятность получения случайного отклонения от установленных с определенной вероятностью результатов. Этот параметр задается вручную и обычно принимает значения: 0.05, 0.01, 0.001.  

**Доверительный интервал** - интервал, в который с заданным уровнем значимости попадает случайная величина  

**Доверительный уровень** - вероятность того, что значение случайной величины попадет в доверительный интервал. Равняется: 1-уровень_значимости    

**Предел погрешности** - статистическая величина, определяющая, с определенной степенью вероятности, максимальное значение, на которое результаты выборки отличаются от результатов генеральной совокупности. Составляет половину длины доверительного интервала.  

**Ковариация** - мера линейной зависимости двух случайных величин (показывает насколько два числа линейно связаны)  
![cov(X,Y) = M[(X - MX)(Y - MY)]](http://bit.ly/2LS1xrh)

**Пример**  
Cредний рост студента первого курса составляет 180 ± 20 см с вероятностью 95 %  
Здесь:  
 - 180 см — среднее значение выборки;  
 - 95 % — доверительная вероятность (коэффициент надёжности);  
 - 160—200 см — доверительный интервал;  
 - 20 см — предел погрешности;   
Толкование: «с вероятностью 95 % истинное среднее значение генеральной совокупности лежит в интервале 160—200 см»  

**Z-нормма (стандартизованная оценка)** -  это мера относительного разброса наблюдаемого или измеренного значения, которая показывает, сколько стандартных отклонений составляет его разброс относительного среднего значения. Это безразмерный статистический показатель используемый для сравнения значений разной размерности или шкалой измерений  
Z = (xs - m) / se  
xs - выборочное среднее  
m - среднее генеральной совокупности  


## Методы оценки качества модели

<img src="./images/confusion-venn.png" width=500 alt="acc-prec-rec" />

Для задачи классификации мы можем рассмотреть confusion-матрицу следующего вида:

|              | Is Obese               | Is Not Obese           |
|--------------|------------------------|------------------------|
| Is Obese     | *TP* - True Positives  | *FP* - False Positives |
| Is Not Obese | *FN* - False Negatives | *TN* - True Negatives  |

Из этой матрицы мы легко можем вывести следующие метрики:
**TPR (Specificity)** - отношение (пропорция) верно классифицированных примеров  
```python
TPR = TP / (TP + FN)
```
**FPR (1 - Specificity)** - отношение (пропорция) ошибочно классифицированных примеров   
```python
FPR = FP / (FP + TN)
```
**Accuracy** - доля правильных ответов алгоритма (отношение верно классифицированных результатов ко всем результатам).  
```python
Accurady = (TP + TN) / (TP + TN + FP + FN)
```
**Misclassification Rate (MISC)** - доля ответов с неверными классами.  
```python
MISC = 100% - Accuracy
```
**Precision** - доля объектов, названных классификатором положительными и при этом действительно являющимися положительными (ошибка первого рода - вероятность принятия неверной гипотезы)  
```python
P = (TP) / (TP + FP)
```
**Recall** (полнота) - какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм (ошибка второго рода - вероятность отвержения верной гипотезы)  
```python
R = (TP) / (TP + FN)
```
**F-мера** - среднее гармоническое presicion и recall  
(можно с различным весом учитывать точность и полноту)  
```python
F = (1 + B^2) * presicion * recall / (B^2 * presicion + recall)
```
B - вес точности в метрике  

**ROC**(Receiver Operating Characteristic curve) - кривая, позволяющая оценить качество бинарной классификации. Представляет собой график, суммирующий представление всех confusion-матриц, которые были образованы в процессе сдвига порогового значения от 0 до 1. ROC-график позволяет выбрать наиболее удовлетворяющее условиям задачи пороговое значение сигмоидальной функции.    
![ROC-AUC](./images/1_pk05QGzoWhCgRiiFbz-oKQ.png)
По оси Y отображается значение TPR - правильно классифицированных примеров  
По оси X - значение FPR - ошибочно классифицированных примеров  

**AUC**(Area Under Curve) - площадь под ROC-кривой. Мы можем построить несколько ROC-кривых для различных моделей классификации, потом посчитать для каждой ROC-кривой ее AUC и на основании этого выбрать лучшую модель.  
 
**Index Dginni** - индекс Джинни
```python
G = 2 * (ROCAUC - 1 / 2)
```

Lift - ???

## Методы измерения ошибок моделей

**Loss function (функция потерь)** - целевая функция, которую минимизируют алгоритмы обучения.   

**L1-норма**
```python
L(y, f) = |y - f|
```
Определяет медиану, более устойчива к выбросам, менее точна  

**L2-норма**
```python
L(y, f) = (y - f)^2
```

**Quantile loss**
Больше штрафует наблюдения оказавшиеся по нужную сторону квантили  

**Logistic loss (Bernoulli loss)**
```python
L(f, y) = log(1 + exp(-2yf))

```
Наиболее часто используема в задачах бинарной классификации  
Особенность в том, что штрафуются даже корректно предсказанные метки классов  

**Adaboost loss**
```python
L(f,y) = exp(-yf)
```
Концептуально эта функция потерь очень похожа на Logistic loss, но имеет более
жесткий экспоненциальный штраф на ошибки классификации и используется реже  

**cross-entropy loss** - среднее число бит между предсказанной и истинной вероятностями 
принадлежности к классу  
![cross-entropy loss](https://wikimedia.org/api/rest_v1/media/math/render/svg/9d83fbf47ec6b26a4d63e9a07f919ec2a0b8f081)
```python
p - предсказанная вероятность  
q - истинная
```

**MSE(Mean squared error)** - показывает среднеквадратичную ошибку
Хороша своей дифференцируемостью, плоха тем, что на выходе дает квадратичную величину, которой
сложно пользоваться
![MSE](https://miro.medium.com/max/4310/1*vkgzQYMaYeM71bmBYuufUw.png)  
При наличии выбросов, они получают большее внимание (размер коррекции весов), что приводит к большему влияюнию 

**MAE Mean absolute error** - размер абсолютной ошибки
![MAE](https://miro.medium.com/max/4750/1*pSJ6h_P-tCAdSJpdpE56Mg.png)  
Данная метрика более устойчива по отношении к выбросам.  

**RMSE (Root Mean squared error)** - корень из MSE. Подходит для сравнения двух моделей или
для контроля качества во время обучения, но позволяет определить насколько хорошо модель
решает задачу.
```python
       SUM(y[i] - y[i]`)^2
SQRT(–––––––––––––––––––––––)
              l
```

**R2** - коэффициент детерминации

**SSE (sum of squared error)** 
```python
SUM(y[i] - y[i]`)^2
```


**Регуляризация** - борьба с переобучением модели

**Оптимизация гиперпараметров** - механизм поиска оптимальных параметров модели с учетом минимизации функции потрерь  

**Распределение Бернулли** — дискретное распределение вероятностей, моделирующее случайный эксперимент произвольной природы, при заранее известной вероятности успеха или неудачи.  

**Least squares method (метод наименьших квадратов)** - метод подбора коэффициентов модели основанный на
минимизации суммы квадратов отклонений некоторых функций от искомых переменных  
```python
SUM( y[i] - f(x[i]) )^2 => min
```

[Хорошая статья по loss-функциям](https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0)  


## Нормировка данных
Зачастую бывает необходимо выравнять данные относительно центра координат.
Для этого можно использовать:
 - StandardScaler - нормализует набор данных таким образом, чтобы каждый столбец X имел mean=0 и std=1  
 - MinMaxScaler  

## Подбор гиперпараметров

**Grid Search** - метод грубого подбора гиперпараметров модели путем перебора значений по сетке с заданным шагом  
**Random Search** - метод перебора гиперпараметров с целью поиска максимума оптимизируемой функции (не требует, чтобы функция была непрерывной)  
**Bayesian optimization**
**Gradient-based optimization**
**Evolutionary optimization** - эволюционные отбор)


### Метрики

**Cartesian product** - Евклидово произведение  
**косинусное расстояние** - довольно большая формула, часто используется для определения расстояния между текстами. Каждый документ описывается вектором, каждая компонента которого соответствует слову из словаря. Компонента равна единице, если соответствующее слово встречается в тексте, и нулю в противном случае. Тогда косинус между двумя векторами будет тем больше, чем больше слов встречаются в этих двух документах одновременно.
[Вот основные метрики](https://delirium-00.livejournal.com/7215.html)  

**[Нормированная z-оценка (Z-score)](#z-norm)**
```python
X` = (X - mean) / sigma
```
 - чрезвачайно важный показатель. Позволяет избавиться от выбросов данных  
Пример использования:
```python
newtrain = train[(np.abs(stats.zscore(train.select_dtypes(include=np.number))) < 3).all(axis=1)]
```
Математический смысл данной операции:  
<img src="./images/FJyli3W.jpg" width="450" alt="zscore" />


### Комбинирование моделей

#### Ансамбль
Набор моделей голосуют, результат определяется заданным образом (через кворум или же наибольшее значение или ...)  
При этом, стоит заметить, что модели обучаются независимо  

#### Бэггинг
Пример - RandomForest  
Является подвидом ансамблей  

#### Бустинг
Является подвидом ансамблей  
Суть в том, что мы и обучаем модели совместно, и используем в дальнейшем  


## notes
### Работа с категориальными признаками
Приведение категориальных текстовых признаков к числовым надо делать с осторожностью. Не стоит приводить данные к числам и оставлять все в одном столбце, т.к мы таким образом создадим возможность вычитать и складывать эти значения и определим функцию расстояния между ними. Вместо этого при приведении категориальные признаков к числовым необходимо распределять признаки по различным столбцам.


Ссылки, источники:
 - [1. Выборочная несмещенная дисперсия - отличнейшая статья](https://statanaliz.info/statistica/opisanie-dannyx/vyborochnaya-dispersiya/)  
