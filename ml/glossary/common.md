## Основные термины и определения

**Математическое ожидание** — среднее значение случайной величины при стремлении количества выборок или количества её измерений (количества испытаний) к бесконечности. Среднее арифметическое случайной величины конечного числа испытаний обычно называют оценкой математического ожидания  

**Дисперсия** - мера разброса случайной величины относительно ее математического ожидания  
![\sigma ^{2} =  \frac{ \sum_0^n ( x_{i} -  \overline{x}  ) }{n - 1} ](http://bit.ly/2ZAPabf)

**Стандартное откл-е/среднеквадратическое откл-е(std)** - показатель рассеивания значений случайной величины относительно её математического ожидания (равняется корню из дисперии)   
![ \sigma =  \sqrt{  \sigma ^{2} } ](http://bit.ly/2LtBS6F)

**Медиана** - значение, которое делит выборку таким образом, что ровно половина ее будет больше, а другая меньше. Медиана не обязательно совпадает со средним значением. Отклонение медианы от среднего называется перекосом данных  
<img src="./images/syb5i0F.png" width=500 alt="Divergence diagram" />
**skewness** - характеристика того, насколько сильно мода отличается от среднего.
skewness может быть положительным и отрицательным в зависимости от смещения распределения  

**Стандартная ошибка** -  величина, характеризующая стандартное отклонение выборочного среднего, рассчитанное по выборке размера n из генеральной совокупности - SD  
```python
SD = sigma / sqrt(n)
```

**Уровень значимости** - обозначает вероятность получения случайного отклонения от установленных с определенной вероятностью результатов. Этот параметр задается вручную и обычно принимает значения: 0.05, 0.01, 0.001.  

**Доверительный интервал** - интервал, в который с заданным уровнем значимости попадает случайная величина  

**Доверительный уровень** - вероятность того, что значение случайной величины попадет в доверительный интервал. Равняется: 1-уровень_значимости    

**Предел погрешности** - статистическая величина, определяющая, с определенной степенью вероятности, максимальное значение, на которое результаты выборки отличаются от результатов генеральной совокупности. Составляет половину длины доверительного интервала.  

**Ковариация** - мера линейной зависимости двух случайных величин (показывает насколько два числа линейно связаны)  
![cov(X,Y) = M[(X - MX)(Y - MY)]](http://bit.ly/2LS1xrh)

#### Пример
Cредний рост студента первого курса составляет 180 ± 20 см с вероятностью 95 %
Здесь:
 - 180 см — среднее значение выборки;
 - 95 % — доверительная вероятность (коэффициент надёжности);
 - 160—200 см — доверительный интервал;
 - 20 см — предел погрешности.
Толкование: «с вероятностью 95 % истинное среднее значение генеральной совокупности лежит в интервале 160—200 см»


## Методы оценки качества модели

**TPR** - True Positive Rate  
```python
TPR = TP / (TP + FN)
```

**FPR** - False Positive Rate  
```python
FPR = FP / (FP + TN)
```

<img src="./images/confusion-venn.png" width=500 alt="acc-prec-rec" />

**Accuracy** - доля правильных ответов алгоритма
```python
A = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)
```

**Precision** - доля объектов, названных классификатором положительными и при этом действительно являющимися положительными (ошибка первого рода - вероятность принятия неверной гипотезы)  
```python
P = (true_positive) / (true_positive + false_positive)
```

**Recall** (полнота) - какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм (ошибка второго рода - вероятность отвержения верной гипотезы)  
```python
R = (true_positive) / (true_positive + false_negative)
```

**Misclassification Rate (MISC)** - доля ответов с неверными классами.
```python
MISC = 100% - Accuracy
```

**F-мера** - среднее гармоническое presicion и recall  
(можно с различным весом учитывать точность и полноту)  
```python
F = (1 + B^2) * presicion * recall / (B^2 * presicion + recall)
```
B - вес точности в метрике  
 
**Index Dginni** - индекс Джинни
```python
G = 2 * (ROCAUC - 1 / 2)
```

Lift - ???

## Методы измерения ошибок моделей

**Loss function (функция потерь)** - целевая функция, которую минимизируют алгоритмы обучения.   

**L1-норма**
```python
L(y, f) = |y - f|
```
Определяет медиану, более устойчива к выбросам, менее точна  

**L2-норма**
```python
L(y, f) = (y - f)^2
```

**Quantile loss**
Больше штрафует наблюдения оказавшиеся по нужную сторону квантили  

**Logistic loss (Bernoulli loss)**
```python
L(f, y) = log(1 + exp(-2yf))

```
Наиболее часто используема в задачах бинарной классификации  
Особенность в том, что штрафуются даже корректно предсказанные метки классов  

**Adaboost loss**
```python
L(f,y) = exp(-yf)
```
Концептуально эта функция потерь очень похожа на Logistic loss, но имеет более
жесткий экспоненциальный штраф на ошибки классификации и используется реже  

**cross-entropy loss** - среднее число бит между предсказанной и истинной вероятностями 
принадлежности к классу  
![cross-entropy loss](https://wikimedia.org/api/rest_v1/media/math/render/svg/9d83fbf47ec6b26a4d63e9a07f919ec2a0b8f081)
```python
p - предсказанная вероятность  
q - истинная
```

**MSE(Mean squared error)** - показывает среднеквадратичную ошибку
Хороша своей дифференцируемостью, плоха тем, что на выходе дает квадратичную величину, которой
сложно пользоваться
![MSE](https://miro.medium.com/max/4310/1*vkgzQYMaYeM71bmBYuufUw.png)  
При наличии выбросов, они получают большее внимание (размер коррекции весов), что приводит к большему влияюнию 

**MAE Mean absolute error** - размер абсолютной ошибки
![MAE](https://miro.medium.com/max/4750/1*pSJ6h_P-tCAdSJpdpE56Mg.png)  
Данная метрика более устойчива по отношении к выбросам.  

**RMSE (Root Mean squared error)** - корень из MSE. Подходит для сравнения двух моделей или
для контроля качества во время обучения, но позволяет определить насколько хорошо модель
решает задачу.
```python
       SUM(y[i] - y[i]`)^2
SQRT(–––––––––––––––––––––––)
              l
```

**R2** - коэффициент детерминации

**SSE (sum of squared error)** 
```python
SUM(y[i] - y[i]`)^2
```


**Регуляризация** - борьба с переобучением модели

**Оптимизация гиперпараметров** - механизм поиска оптимальных параметров модели с учетом минимизации функции потрерь  

**Распределение Бернулли** — дискретное распределение вероятностей, моделирующее случайный эксперимент произвольной природы, при заранее известной вероятности успеха или неудачи.  

**AUC**(Area Under Curve) - 

**ROC**(Receiver Operating Characteristic curve) - кривая, позволяющая оценить качество бинарной классификации  

![ROC-AUC](./images/1_pk05QGzoWhCgRiiFbz-oKQ.png)


**Least squares method (метод наименьших квадратов)** - метод подбора коэффициентов модели основанный на
минимизации суммы квадратов отклонений некоторых функций от искомых переменных  
```python
SUM( y[i] - f(x[i]) )^2 => min
```

[Хорошая статья по loss-функциям](https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0)  


## Нормировка данных
Зачастую бывает необходимо выравнять данные относительно центра координат.
Для этого можно использовать:
 - StandardScaler - нормализует набор данных таким образом, чтобы каждый столбец X имел mean=0 и std=1  
 - MinMaxScaler  

## Подбор гиперпараметров

**Grid Search** - метод грубого подбора гиперпараметров модели путем перебора значений по сетке с заданным шагом  
**Random Search** - метод перебора гиперпараметров с целью поиска максимума оптимизируемой функции (не требует, чтобы функция была непрерывной)  
**Bayesian optimization**
**Gradient-based optimization**
**Evolutionary optimization** - эволюционные отбор)


### Метрики

**Cartesian product** - Евклидово произведение  
**косинусное расстояние** - довольно большая формула, часто используется для определения расстояния между текстами. Каждый документ описывается вектором, каждая компонента которого соответствует слову из словаря. Компонента равна единице, если соответствующее слово встречается в тексте, и нулю в противном случае. Тогда косинус между двумя векторами будет тем больше, чем больше слов встречаются в этих двух документах одновременно.
[Вот основные метрики](https://delirium-00.livejournal.com/7215.html)  

**[Нормированная z-оценка (Z-score)](#z-norm)**
```python
X` = (X - mean) / sigma
```
 - чрезвачайно важный показатель. Позволяет избавиться от выбросов данных  
Пример использования:
```python
newtrain = train[(np.abs(stats.zscore(train.select_dtypes(include=np.number))) < 3).all(axis=1)]
```
Математический смысл данной операции:  
<img src="./images/FJyli3W.jpg" width="450" alt="zscore" />


### Комбинирование моделей

#### Ансамбль
Набор моделей голосуют, результат определяется заданным образом (через кворум или же наибольшее значение или ...)  
При этом, стоит заметить, что модели обучаются независимо  

#### Бэггинг
Пример - RandomForest  
Является подвидом ансамблей  

#### Бустинг
Является подвидом ансамблей  
Суть в том, что мы и обучаем модели совместно, и используем в дальнейшем  


## notes
### Работа с категориальными признаками
Приведение категориальных текстовых признаков к числовым надо делать с осторожностью. Не стоит приводить данные к числам и оставлять все в одном столбце, т.к мы таким образом создадим возможность вычитать и складывать эти значения и определим функцию расстояния между ними. Вместо этого при приведении категориальные признаков к числовым необходимо распределять признаки по различным столбцам.
