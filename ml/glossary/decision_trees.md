# Деревья принятия решений

Основная идея - максимальное уменьшение энтропии после прохождения каждого предиката  
Для расчета энтропии используется одна из формул:

## [Энтропия Шеннона](#shennon-entropy)
```python
S = -SUM(p[i] * log2(p[i]))
```
p[i] - вероятность нахождения системы в i-ом состоянии

## [Энтропия Джинни](#ginni-entropy)
```python
G = 1 - SUM(p[i]^2)
```

Способы борьбы с переобучением:
 - стрижка  
 - ограничение глубины  

## RandomForest (случайный лес)
Усреднение ответов деревьев построенных до максимальной глубины  

Преимущества:
 - интерпретируемость и визуализируемость  
 - быстрый процесс обучения и прогнозирования  
 - малое число параметров модели  
 - поддержка числовых и категориальных признаков  

Недостатки:
 - высокая чувствительность к шумам в данных  
 - дерево умееть только интерполировать, но не экстраполировать  
