# Boosting

Идея бустинга в том, чтобы использовать ансамбли более слабых моделей  

### GBM (Градиентный бустинг)
Использует идею: на каждом шаге обучения корректировать те
модели (обычно это деревья), которые выдали наиболее далекий от верного ответ 

Для работы бустинга необходимо:
 - выбрать функцию потерь
 - выбрать семейство функций на которых будет обучаться модель
 - выбрать дополнительные гиперпараметры (например, глубина деревьев)

### AdaBoost (adaptive boosting)
Имеет целью объединение нескольких слабых классификаторов в один сильный.  
[Ссылка](https://towardsdatascience.com/boosting-algorithm-adaboost-b6737a9ee60c)  

Существуют различные алгоритмы для обучения моделей деревьев: CART, C4.5, CHAID.
