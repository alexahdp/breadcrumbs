# Классификационные модели

## Logistic Regression
Логистическая регрессия — это статистическая модель, используемая для прогнозирования вероятности возникновения некоторого события путём подгонки данных к логистической кривой  
Для логистической регресси характерно то, что выходные значения равны: [0, 1]  
А функция вероятности принадлежности к одному из классов представляет собой логистическую функцию - сигмойд  
```python
  f(x) = 1 / (1 + e^-x)
```


## SVM (support vector machine)
Метод опорных векторов
Основная идея метода — перевод исходных векторов в пространство более высокой размерности и поиск разделяющей гиперплоскости с максимальным зазором в этом пространстве  
Требует нормировки данных  
Мы строим гиперплоскость, резделяющую данные на два класса, а затем еще две гиперплоскости
по бокам и стараемся максимизировать расстояние между ними  
[Описание](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%BF%D0%BE%D1%80%D0%BD%D1%8B%D1%85_%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BE%D0%B2)


## Decision Trees
[см decision trees](./decision_trees.md)


# Методы кластеризации

## KMeans
Алгоритм, стремящийся минимизировать суммарное квадратичное отклонение точек кластеров от центров этих кластеров.
Центроиды - центры кластеров.
На первоначальном этапе выбираются либо случайные координаты центроидов, либо по определенному правилу.
Затем на каждом этапе происходит подсчет евклидова расстояния для каждого признака к каждому центроиду и выбор минимального (классификация).
Затем центроид для каждого кластера перевычисляет свои координаты  
Алгоритм останавливается когда координаты центроид перестают меняться более, чем на заданную m величину.  
Недостатки:  
 - число кластеров разбивки необходимо знать заранее  
 - не гарантируется достижение глобального минимума суммарного квадратичного отклонения V, а только одного из локальных минимумов  
 - результат зависит от выбора исходных центров кластеров, их оптимальный выбор неизвестен  


## HDBSCAN
Метод основан на плотности данных. Необходимо задать минимальное пороговое значение
для образования кластера.
(является улучшенной версией DBSCAN)
Преимущества:
 - не требует задания количества кластеров при старте обуяения  
 - может определять отдельные данные как шум
