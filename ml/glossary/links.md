## Полезные ссылки
 - [How to clean your Data ?](https://www.kaggle.com/amrmahmoud123/how-to-clean-your-data)  
 - [Dive into Machine Learning](https://github.com/hangtwenty/dive-into-machine-learning)  
 - [Другой Github 2: машинное обучение, датасеты и Jupyter Notebooks](https://habr.com/ru/company/mailru/blog/445530/)  
 - [Лучшие датасеты для машинного обучения и анализа данных](https://tproger.ru/translations/the-best-datasets-for-machine-learning-and-data-science/)  
 - [Тонкая настройка нейронной сети - замечательная статья](https://habr.com/ru/company/wunderfund/blog/315476/)  
 - [Работа с несбалансированными данными - inbalanced, imblearn](https://towardsdatascience.com/a-deep-dive-into-imbalanced-data-over-sampling-f1167ed74b5)
 - [Отличная статья по word embedding](https://habr.com/ru/company/ods/blog/329410/)  
 - [Набор готовых embedding-ов английских слов от facebook](https://www.kaggle.com/yekenot/fasttext-crawl-300d-2m)  
 - [NLP - Про лексер, лемматизацию и стэмминг](http://www.solarix.ru/for_developers/docs/tokenizer.shtml)  
 - [Метрики качества ранжирования](https://habr.com/ru/company/econtenta/blog/303458/)  
 - [Большой список подкастов по DataScience](https://realpython.com/data-science-podcasts/)  
 - [Введение в архитектуры нейронных сетей(2019) - отличная обзорная статья](https://habr.com/ru/company/oleg-bunin/blog/340184/)  
 - [Краткое описание принципа работы BERT](https://habr.com/ru/post/436878/)  
 - [Прекрасное объяснение что такое "Линейная" регрессия](https://towardsdatascience.com/what-is-linear-regression-model-f24f1a24f9bb)  
 - [Всё, что вы знали о word2vec, неправда](https://habr.com/ru/post/454926/)  
 - [Tensorflow Embedding Projector](https://towardsdatascience.com/visualizing-bias-in-data-using-embedding-projector-649bc65e7487)
 - [Статья про разработку LSTM + ссылки](https://habr.com/ru/post/452356/)  
 - [Local Response Normalization(LRN)](https://towardsdatascience.com/difference-between-local-response-normalization-and-batch-normalization-272308c034ac)  
